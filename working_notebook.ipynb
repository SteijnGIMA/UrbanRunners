{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import folium\n",
    "import geopandas as gpd #A more flexible package to work with geospatial data in python \n",
    "from itertools import product\n",
    "import json\n",
    "import networkx as nx # networkx package \n",
    "import numpy as np\n",
    "from osgeo import ogr #GDAL package \n",
    "import osmnx as ox \n",
    "import pandas as pd #Base package for data analysis and manipulation \n",
    "from pyproj import CRS #package for your projection management \n",
    "import random\n",
    "import rasterio as rio\n",
    "from rasterio import mask\n",
    "import rasterstats as rs\n",
    "import requests\n",
    "import shapely.geometry #python package for basic spatial operation \n",
    "import xml.dom.minidom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sections of this notebook are in order. \n",
    "The OSM settings should always be run.\n",
    "Some of the operations in this notebook require data that can be downloaded from the data folder in this repository.\n",
    "\n",
    "Downloading the AHN4 datasets can take quite some time, so make sure you have everything set up right before you do that. This also counts for downloading the networks.\n",
    "\n",
    "The section with OSMOSIS can be ignored for now, but might be necessary for later if the downloading of network via OSMnx fails for some reason.\n",
    "\n",
    "Adding grid value section is a work in progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OSM settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adds surface as extra tag for the edges (THIS IS A REQUIRED STEP BEFORE YOU DOWNLOAD THE NETWORK)\n",
    "ox.settings.useful_tags_way.extend(['surface','footway','cycleway', 'crossing', 'barrier'])\n",
    "ox.settings.useful_tags_node.extend(['barrier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NETWERK EXTENT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gemeentenaam\n",
       "Utrecht      POLYGON ((4.94185 52.02589, 4.94070 52.14183, ...\n",
       "Amsterdam    POLYGON ((4.70129 52.27695, 4.69890 52.43084, ...\n",
       "Den_Haag     POLYGON ((4.16227 52.01354, 4.15916 52.12691, ...\n",
       "Rotterdam    POLYGON ((3.93606 51.83744, 3.93082 51.99951, ...\n",
       "Name: extent, dtype: geometry"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the city names\n",
    "g_namen = ['Amsterdam', 'Rotterdam', \"Den_Haag\", \"Utrecht\"]\n",
    "\n",
    "#download city geometries from file\n",
    "project_gemeenten = gpd.read_file(r\"data\\boundaries\\UrbanRunner_Areas.geojson\") ## dit komt van de cbs gemeentegrenzen. Beschrijven bij data\n",
    "\n",
    "\n",
    "#set additional geometry column of extent\n",
    "project_gemeenten[\"extent\"] = project_gemeenten.envelope.buffer(2000).to_crs(\"EPSG:4326\")\n",
    "\n",
    "#set index to gemeentenaam column\n",
    "project_gemeenten.set_index('gemeentenaam', inplace=True)\n",
    "\n",
    "#project to WGS84\n",
    "project_gemeenten.to_crs(\"EPSG:4326\", inplace=True)\n",
    "project_gemeenten['extent'].to_crs(\"EPSG:4326\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### plot in folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_centroid = project_gemeenten.unary_union.envelope.centroid.coords[0]\n",
    "\n",
    "#create folium map\n",
    "m = folium.Map(location = (map_centroid[1], map_centroid[0]))\n",
    "#plot the convexhulls of each network region in the folium map\n",
    "for _, r in project_gemeenten.iterrows():\n",
    "    #unbuffered convex hull\n",
    "    extent = gpd.GeoSeries(r[\"extent\"])\n",
    "    extent_j = extent.to_json()\n",
    "    extent_j = folium.GeoJson(data=extent_j,\n",
    "                           style_function=lambda x: {'fillColor': 'blue'})\n",
    "    folium.Popup(r.name).add_to(extent_j)\n",
    "    extent_j.add_to(m)\n",
    "\n",
    "    #orginal geometry\n",
    "    geom = gpd.GeoSeries(r['geometry'])\n",
    "    geom_j = geom.to_json()\n",
    "    geom_j = folium.GeoJson(data=geom_j,\n",
    "                           style_function=lambda x: {'fillColor': 'green'})\n",
    "    folium.Popup(r.name).add_to(geom_j)\n",
    "    geom_j.add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOWNLOADING AHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahn_datavlakken = gpd.read_file(r\"data/kaartbladen_AHN4.gpkg\") ## AHN4 data beschrijven in methode. Kaartbladen_AHN4 bestaan uit tiles met download links naar verschillende varianten van AHN4. Wij gebruiken AHN4_0.5M_DTM. Beschrijven waarom deze wordt gepakt.\n",
    "ahn_datavlakken.to_crs(\"EPSG:4326\", inplace=True)\n",
    "for g in [\"Amsterdam\"]:\n",
    "    globals()[f\"{g}_ahnvlakken\"]=ahn_datavlakken.clip(project_gemeenten.loc[g].extent.envelope) ## Beschrijven in de methode hoe de juiste tiles wordt gekozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gemeente in g_namen:\n",
    "    globals()[f\"{gemeente}_ahnvlakken\"]=ahn_datavlakken.clip(project_gemeenten.loc[gemeente].extent.envelope)\n",
    "    for i in range(globals()[f\"{gemeente}_ahnvlakken\"].Name_1.count()):    \n",
    "        name = globals()[f\"{gemeente}_ahnvlakken\"].iat[i,2]\n",
    "\n",
    "        response = requests.get(globals()[f\"{gemeente}_ahnvlakken\"].iat[i,3])\n",
    "        print('done with downloading number ' + i + ' of gemeente ' + gemeente)\n",
    "        open('C:\\\\Users\\\\danny\\\\Documents\\\\persoonlijk\\\\GIMA\\\\modules\\\\module 6\\\\data\\\\AHN4_05M_DTM\\\\'+gemeente + '\\\\'+ name + '.zip', \"wb\").write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in ['Amsterdam']:\n",
    "    globals()[f\"{g}_DTM_list\"] = []\n",
    "    for i in range(globals()[f\"{g}_ahnvlakken\"].Name_1.count()):    \n",
    "        name = globals()[f\"{g}_ahnvlakken\"].iat[i,2]\n",
    "        globals()[f\"{g}_DTM_list\"].append('C:\\\\Users\\\\danny\\\\Documents\\\\persoonlijk\\\\GIMA\\\\modules\\\\module 6\\\\data\\\\AHN4_05M_DTM\\\\'+ g + '\\\\M_'+ name +\".tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GETTING NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for getting the real deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify false\n",
    "for g in g_namen: ## beschrijven dat er twee netwerken worden gepakt: van walk en van bike, en dat deze dan worden samengevoegd met de networkx compose functie. \n",
    "    print('starting with', g)\n",
    "    globals()[f\"{g}_network_walk\"] = ox.graph_from_polygon(project_gemeenten.loc[g].extent.envelope, network_type=\"walk\", retain_all=True ,simplify=False) ## we hebben gekozen voor simplify false. Beschrijven wat dit inhoudt ahv osmnx documentation. We hebben de dijkstra algoritme getest op twee netwerken, één met simplify aan en de ander met simplify uit. Er was wel een verschil, maar niet groot genoeg om simplify te gebruiken. Retain_all= true moet ook worden uitgelegd waarom. Dit is namelijk omdat we twee verschillende netwerken samenvoegen, en dat we daarna de niet verbonden edges er afgooien.\n",
    "    print('done with walking graph of', g)\n",
    "    globals()[f\"{g}_network_bike\"] = ox.graph_from_polygon(project_gemeenten.loc[g].extent.envelope, network_type=\"bike\", retain_all=True, simplify=False)\n",
    "    print('done with biking graph of', g)\n",
    "    globals()[f\"{g}_network_both\"] = nx.compose(globals()[f\"{g}_network_walk\"], globals()[f\"{g}_network_bike\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for testing (small network extent within Utrecht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with walking network\n",
      "done with biking network\n",
      "done with walking network\n",
      "done with biking network\n"
     ]
    }
   ],
   "source": [
    "#small network for testing\n",
    "# simplify True\n",
    "for g in [\"Utrecht\"]:\n",
    "    globals()[f\"{g}_network_walk_test\"] = ox.graph_from_polygon(project_gemeenten.loc[g].extent.envelope, network_type=\"walk\")\n",
    "    print('done with walking network')\n",
    "    globals()[f\"{g}_network_bike_test\"] = ox.graph_from_polygon(project_gemeenten.loc[g].extent.envelope, network_type=\"bike\")\n",
    "    print('done with biking network')\n",
    "    globals()[f\"{g}_network_both_test_simplified\"] = nx.compose(globals()[f\"{g}_network_walk_test\"], globals()[f\"{g}_network_bike_test\"])\n",
    "\n",
    "#simplify false\n",
    "for g in [\"Utrecht\"]:\n",
    "    globals()[f\"{g}_network_walk_test\"] = ox.graph_from_polygon(project_gemeenten.loc[g].extent.envelope, network_type=\"walk\", simplify=False)\n",
    "    print('done with walking network')\n",
    "    globals()[f\"{g}_network_bike_test\"] = ox.graph_from_polygon(project_gemeenten.loc[g].extent.envelope, network_type=\"bike\", simplify=False)\n",
    "    print('done with biking network')\n",
    "    globals()[f\"{g}_network_both_test\"] = nx.compose(globals()[f\"{g}_network_walk_test\"], globals()[f\"{g}_network_bike_test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_XY_in_polygon(poly): ## manier om XY coordinaten te pakken binnen een polygon\n",
    "    minx, miny, maxx, maxy = poly.bounds\n",
    "    while True:\n",
    "        p = shapely.geometry.Point(random.uniform(minx, maxx), random.uniform(miny, maxy))\n",
    "        if poly.contains(p):\n",
    "            return p.coords[0][0], p.coords[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of nodes\n",
    "n_nodes = 100\n",
    "\n",
    "#getting random nodes\n",
    "for g in g_namen:\n",
    "    X_list = []\n",
    "    Y_list = []    \n",
    "    for i in range(n_nodes):\n",
    "        x, y = get_random_XY_in_polygon(project_gemeenten.loc[g].geometry)\n",
    "        X_list.append(x)\n",
    "        Y_list.append(y)\n",
    "    globals()[f\"{g}_random_nodes\"] = ox.nearest_nodes(globals()[f\"{g}_network_both\"], X_list, Y_list, return_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting nodes from the random XY sets\n",
    "#UNSIMPLIFIED\n",
    "\n",
    "source_nodes = globals()[f\"{g}_random_nodes\"][0][:50]\n",
    "goal_nodes = globals()[f\"{g}_random_nodes\"][0][50:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test: comparing simplified with nonsimplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in [\"Utrecht\"]:\n",
    "    X_list = []\n",
    "    Y_list = []    \n",
    "    for i in range(100):\n",
    "        x, y = get_random_XY_in_polygon(project_gemeenten.loc[g].geometry)\n",
    "        X_list.append(x)\n",
    "        Y_list.append(y)\n",
    "    #random_nodes = ox.nearest_nodes(, X_list, Y_list, return_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting nodes from the random XY sets\n",
    "#UNSIMPLIFIED\n",
    "random_nodes = ox.nearest_nodes(u_network_both, X_list, Y_list, return_dist=True)\n",
    "source_nodes = random_nodes[0][:50]\n",
    "goal_nodes = random_nodes[0][50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting nodes from the random XY sets\n",
    "#UNSIMPLIFIED\n",
    "Utrecht_random_nodes = ox.nearest_nodes(Utrecht_network_both_test, X_list, Y_list, return_dist=True)\n",
    "Utrecht_source_nodes = Utrecht_random_nodes[0][:50]\n",
    "Utrecht_goal_nodes   =    Utrecht_random_nodes[0][50:100]\n",
    "#SIMPLIFIED\n",
    "Utrecht_random_nodes_simplified = ox.nearest_nodes(Utrecht_network_both_test_simplified, X_list, Y_list, return_dist=True)\n",
    "Utrecht_source_nodes_simplified = Utrecht_random_nodes_simplified[0][:50]\n",
    "Utrecht_goal_nodes_simplified   =   Utrecht_random_nodes_simplified[0][50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gathering random routes for unsimplified network takes 31.143508672714233 seconds\n",
      "gathering random routes for simplified network takes 10.06904125213623 seconds\n"
     ]
    }
   ],
   "source": [
    "# calculating shortest route of the source and goal nodes\n",
    "#UNSIMPLIFIED\n",
    "start_time = time.time()\n",
    "random_shortest_routes = ox.distance.shortest_path(\n",
    "    Utrecht_network_both_test, Utrecht_source_nodes, Utrecht_goal_nodes, weight='length', cpus=1)\n",
    "\n",
    "print(\"gathering random routes for unsimplified network takes %s seconds\" % (time.time() - start_time))\n",
    "randomroute_time = (time.time() - start_time)\n",
    "\n",
    "#SIMPLIFIED\n",
    "start_time = time.time()\n",
    "random_shortest_routes_simplified = ox.distance.shortest_path(\n",
    "    Utrecht_network_both_test_simplified, Utrecht_source_nodes_simplified, Utrecht_goal_nodes_simplified, weight='length', cpus=1)\n",
    "    \n",
    "print(\"gathering random routes for simplified network takes %s seconds\" % (time.time() - start_time))\n",
    "randomroute_time_simplified = (time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ox.folium.plot_route_folium(u_network_both, random_shortest_routes[2], route_map=None, popup_attribute=None, tiles='cartodbpositron', zoom=1, fit_bounds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ox.folium.plot_route_folium(u_network_both_simplified, random_shortest_routes_simplified[2], route_map=None, popup_attribute=None, tiles='cartodbpositron', zoom=1, fit_bounds=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USING OSMOSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for ways"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "osmosis --read-xml utrecht-latest.osm --tf accept-ways highway=* --tf reject-ways highway=abandoned,bus_guideway,construction,motor,proposed,planned,raceway,cycleway service=private foot=no access=private --tf reject-relations --used-node --write-xml utrecht_walk.osm\n",
    "osmosis --read-xml utrecht-latest.osm --tf accept-ways highway=* --tf reject-ways highway=abandoned,bus_guideway,construction,motor,proposed,planned,raceway,corridor,elevator,escalator,footway,steps service=private bicycle=no access=private --tf reject-relations --used-node --write-xml utrecht_bike.osm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "osmosis --read-pbf utrecht-latest.osm.pbf --tf accept-ways highway=* --used-node --write-xml highways.osm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "osmosis --read-xml utrecht_combination.osm --bounding-box left=4.940698126246746 bottom=52.00802236935806 right=5.224513606042486 top=52.16049477581679 --write-xml utrecht_combination_extent.osm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for greenspaces\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "osmosis --read-xml utrecht-latest.osm --bounding-box left=4.940698126246746 bottom=52.00802236935806 right=5.224513606042486 top=52.16049477581679 --tf accept-ways landuse=village_green,recreation_ground,grass,forest leisure=park,garden,nature_reserve natural=fell,heath,wood --tf accept-nodes landuse=village_green,recreation_ground,grass,forest leisure=park,garden,nature_reserve natural=fell,heath,wood --tf reject-relations --write-xml utrecht_greenspaces.osm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COUNTING greenspace per type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = xml.dom.minidom.parse(r\"data/OSM/utrecht_greenspaces.osm\")\n",
    "\n",
    "ways = doc.getElementsByTagName('way')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wayWithLanduse = []\n",
    "wayWithLeisure = []\n",
    "wayWithNatural = []\n",
    "for way in ways:\n",
    "    for way_child in way.childNodes:\n",
    "        if type(way_child) == xml.dom.minidom.Text:\n",
    "            continue\n",
    "        elif way_child.hasAttribute('k'):\n",
    "            if way_child.getAttribute('k') == 'landuse': \n",
    "                wayWithLanduse.append(way)\n",
    "            elif way_child.getAttribute('k') == 'leisure':\n",
    "                wayWithLeisure.append(way)\n",
    "            elif way_child.getAttribute('k') == 'natural':\n",
    "                wayWithNatural.append(way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(wayWithLeisure), len(wayWithLanduse), len(wayWithNatural))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GREENSPACES, WATERTAPS AND OBSTACLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in [\"Utrecht\"]:\n",
    "    globals()[f\"greenspaces_{g}\"] = ox.geometries_from_polygon(project_gemeenten.loc[g].extent.envelope, tags={'landuse':['village_green','recreation_ground','grass','forest'], 'leisure':['nature_reserve','park','garden'],'natural':['fell','heath','wood']}) ## beschrijven\n",
    "    globals()[f\"greenspaces_{g}\"] = globals()[f\"greenspaces_{g}\"].loc['way'][[\"geometry\",\"natural\",\"leisure\",\"landuse\"]]\n",
    "\n",
    "    globals()[f\"waterpoints_{g}\"] = ox.geometries_from_polygon(project_gemeenten.loc[g].extent.envelope, tags={'amenity':'drinking_water'})\n",
    "    globals()[f\"waterpoints_{g}\"].to_crs('EPSG:28992', inplace=True)\n",
    "    globals()[f\"waterpoints_{g}\"]['buffered'] = globals()[f\"waterpoints_{g}\"].buffer(50) ## dit moet worden onderbouwd: waarom 50 meter buffer? & in de discussie: watertappunten is lastig, want je wilt niet na 100m al langs een watertappunt lopen\n",
    "    globals()[f\"waterpoints_{g}\"].set_geometry('buffered', inplace=True, crs=\"EPSG:28992\")\n",
    "    globals()[f\"waterpoints_{g}\"].to_crs('EPSG:4326', inplace=True)\n",
    "    globals()[f\"waterpoints_{g}\"] = globals()[f\"waterpoints_{g}\"][['amenity','buffered']]\n",
    "\n",
    "    globals()[f\"obstruction_{g}\"] = ox.geometries_from_polygon(project_gemeenten.loc[g].extent.envelope, tags={'barrier':['gate', 'stile'], 'footway':'crossing', 'cycleway':'crossing'}) ## barriers beschrijven, hiernaast wordt ook gebruik gemaakt van traffic signals, die al inherent in het netwerk is\n",
    "    globals()[f\"obstruction_nodes_{g}\"] = globals()[f\"obstruction_{g}\"].loc['node']['barrier']\n",
    "    globals()[f\"obstruction_ways_{g}\"] = globals()[f\"obstruction_{g}\"].loc['way'][['footway','cycleway']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### adding to node and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in g_namen:\n",
    "    globals()[f\"{g}_edges\"] = gpd.sjoin(globals()[f\"{g}_edges\"], globals()[f\"greenspaces_{g}\"], how = 'left')\n",
    "    globals()[f\"{g}_edges\"] = gpd.sjoin(globals()[f\"{g}_edges\"], globals()[f\"waterpoints_{g}\"], how = 'left')\n",
    "    globals()[f\"{g}_edges\"] = gpd.sjoin(globals()[f\"{g}_edges\"], globals()[f\"waterpoints_{g}\"], how = 'left')\n",
    "    globals()[f\"{g}_nodes\"] = gpd.sjoin(globals()[f\"{g}_nodes\"], globals()[f\"obstruction_nodes_{g}\"], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GETTING EDGE CLIMB FROM NODE ELEVATION (WORK IN PROGRESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVING NETWORKS TO GEOPACKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving networks\n",
    "def saving_networks(network):\n",
    "    ox.save_graph_geopackage(network, filepath='data\\\\graphs\\\\' + g + '_Graph_complete.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADDING HEAT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, right, bottom, top = 185250, 197000, 438500, 447500\n",
    "gpd.GeoDataFrame({'geometry': shapely.geometry.box(left, bottom, right, top)}, index=[0], crs=\"EPSG:28992\").to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.GeoDataFrame({\"geometry\": project_gemeenten.to_crs(\"EPSG:28992\").loc['Utrecht'].extent.envelope}, index=[0], crs=\"EPSG:4326\").to_crs(\"EPSG:28992\").to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid_update(polygon, edge_size):\n",
    "    \"\"\"\n",
    "    polygon : shapely.geometry\n",
    "    edge_size : length of the grid cell\n",
    "    \"\"\"\n",
    "    bounds = polygon.bounds\n",
    "    x_rest = edge_size - (bounds[2]-bounds[0])%edge_size\n",
    "    y_rest = edge_size - (bounds[3]-bounds[1])%edge_size\n",
    "    x_coords = np.arange(bounds[0] - x_rest/2 + edge_size/2, bounds[2] + x_rest/2, edge_size)\n",
    "    y_coords = np.arange(bounds[1] - y_rest/2 + edge_size/2, bounds[3] + y_rest/2, edge_size)\n",
    "    combinations = np.array(list(product(x_coords, y_coords)))\n",
    "    squares = gpd.points_from_xy(combinations[:, 0], combinations[:, 1]).buffer(edge_size / 2, cap_style=3)\n",
    "    return gpd.GeoSeries(squares[squares.intersects(polygon)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess PET map\n",
    "rastfile = rio.open('data/RIVM_R88_20170621_gm_actueelUHI.tif') # \n",
    "bboxshape = [json.loads(gpd.GeoDataFrame({\"geometry\": project_gemeenten.to_crs(\"EPSG:28992\").loc['Utrecht'].extent.envelope}, \n",
    "    index=[0], crs=\"EPSG:4326\").to_crs(\"EPSG:28992\").to_json())['features'][0]['geometry']]\n",
    "petmap, petmap_transform = mask.mask(rastfile, shapes=bboxshape, crop=True)\n",
    "with rio.open('hittedata.tif', 'w', driver=\"GTiff\",\n",
    "                   height=petmap.shape[1], width=petmap.shape[2], \n",
    "                   transform=petmap_transform, crs=CRS.from_epsg(28992),\n",
    "                   nodata=255, dtype='uint8', count= 1) as file:\n",
    "    file.write(petmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1705, 1953)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "petmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EnrichEdgesWithRasterInfo(edges, raster, statsprefix):\n",
    "    edges['UID'] = range(0, len(edges)) # add a temporary Unique ID column\n",
    "    e = edges.loc[:, ['UID', 'geometry']] # make subset of relevant columns\n",
    "    e_zonalstats = rs.zonal_stats(e, raster, prefix=statsprefix, geojson_out=True) # perform spatial overlay/ zonal statistics and add statistics\n",
    "    e_props = pd.DataFrame.from_dict(e_zonalstats).properties # convert to dataframe and select only the properties (results again in dictionary)\n",
    "    e_propsdf = pd.DataFrame.from_dict(list(e_props)) # convert dictionary with properties to a pandas dataframe\n",
    "    edges_updated = edges.join(other=e_propsdf.set_index('UID'), on=('UID')) # join stats to the original edges and save as updated edges\n",
    "    return edges_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAPH FROM GEOPACKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in [\"Utrecht\", \"Den_Haag\"]:\n",
    "    fp = 'data/graphs_team/'+g+'_Graph.gpkg'\n",
    "    globals()[f\"{g}_nodes\"] = gpd.read_file(fp, layer='nodes').set_index('osmid')\n",
    "    globals()[f\"{g}_edges\"] = gpd.read_file(fp, layer='edges').set_index(['u', 'v', 'key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rotterdam_nodes.to_file(\"data/graphs/reprojected/Rotterdam_Graph.gpkg\", layer=\"nodes\", driver=\"GPKG\")\n",
    "Rotterdam_edges.to_file(\"data/graphs/reprojected/Rotterdam_Graph.gpkg\", layer=\"edges\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Utrecht_nodes.crs, Den_Haag_nodes.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Den_Haag_edges.crs = \"EPSG:28992\"\n",
    "Den_Haag_nodes.crs = \"EPSG:28992\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Den_Haag_edges.to_crs(\"EPSG:4326\", inplace=True)\n",
    "Den_Haag_nodes.to_crs(\"EPSG:4326\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utrecht_nodes.to_file(\"data/graphs/reprojected/Utrecht_Graph.gpkg\", layer=\"nodes\", driver=\"GPKG\")\n",
    "Utrecht_edges.to_file(\"data/graphs/reprojected/Utrecht_Graph.gpkg\", layer=\"edges\", driver=\"GPKG\")\n",
    "Den_Haag_nodes.to_file(\"data/graphs/reprojected/Den_Haag_Graph.gpkg\", layer=\"nodes\", driver=\"GPKG\")\n",
    "Den_Haag_edges.to_file(\"data/graphs/reprojected/Den_Haag_Graph.gpkg\", layer=\"edges\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_from_geopackage(gemeente):  \n",
    "    fp = 'data/graphs/'+g+'_Graph.gpkg'\n",
    "    gdf_nodes = gpd.read_file(fp, layer='nodes').set_index('osmid')\n",
    "    gdf_edges = gpd.read_file(fp, layer='edges').set_index(['u', 'v', 'key'])\n",
    "    assert gdf_nodes.index.is_unique and gdf_edges.index.is_unique\n",
    "    # convert the node/edge GeoDataFrames to a MultiDiGraph\n",
    "    graph_attrs = {'crs': 'epsg:4326', 'simplified': True}\n",
    "    G = ox.graph_from_gdfs(gdf_nodes, gdf_edges, graph_attrs)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in [\"Amsterdam\", \"Rotterdam\", \"Den_Haag\"]:\n",
    "    G1 = graph_from_geopackage(g)\n",
    "    G2 = ox.utils_graph.get_largest_component(G1)\n",
    "    ox.save_graph_geopackage(G2, filepath='data\\\\graphs\\\\' + g +'_Graph.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utrecht_Graph = ox.utils_graph.get_largest_component(Utrecht_Graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ox.save_graph_geopackage(Utrecht_Graph, filepath='data\\\\graphs\\\\Utrecht_Graph.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(G2.nodes), len(G3.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Utrecht_Graph.nodes)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74868beb4ec27fd26d4cf7f91852fff1668a283e4d2efd66b1e888f5eef2fc2a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 ('ox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
